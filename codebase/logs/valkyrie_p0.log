2025-10-13 13:03:58,535 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-13 13:03:58,536 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-13 13:03:58,537 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:23:06,478 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:23:06,479 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:23:47,723 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:23:47,724 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:24:32,438 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:24:32,440 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:26:49,680 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:26:49,684 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:28:29,307 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:28:29,310 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:29:23,597 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:29:23,600 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:29:48,495 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:29:48,498 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:31:17,745 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:31:17,748 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:32:51,547 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:32:54,549 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:36:44,641 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:36:48,113 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:38:39,224 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:38:42,411 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:39:56,983 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:40:02,595 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:41:03,551 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:41:06,553 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:41:19,653 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:41:22,581 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:44:23,916 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:44:27,631 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:45:27,155 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:45:30,373 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 11:46:17,557 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 11:46:20,822 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 12:06:06,868 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 12:07:35,509 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 12:07:35,512 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 12:09:18,277 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 12:09:18,280 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-22 12:20:40,446 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-22 12:20:40,449 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-23 05:13:03,190 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-23 05:15:34,470 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-23 05:18:14,404 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-23 05:18:26,046 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-23 05:24:40,382 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-23 05:29:15,937 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-23 08:04:28,125 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-23 08:13:02,202 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-23 08:15:43,954 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-23 08:42:10,279 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-23 08:48:28,701 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-23 15:30:21,785 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-23 16:41:35,315 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-23 16:41:37,714 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 00:17:16,444 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 00:17:39,812 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 00:21:44,885 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 00:22:41,998 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 00:23:31,801 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 00:26:45,087 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 00:28:05,841 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 00:40:44,812 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 09:51:01,273 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-24 09:51:01,273 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 09:51:01,275 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 09:52:57,214 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-24 09:52:57,215 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 09:52:57,217 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 09:53:55,077 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-24 09:53:55,078 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 09:53:55,082 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 09:55:14,149 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-24 09:55:14,149 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 09:55:14,153 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 09:55:53,818 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-24 09:55:53,818 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 09:56:07,026 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 09:57:05,003 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-24 09:57:05,004 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:11:31,216 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 10:15:51,372 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-24 10:15:51,373 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:16:21,996 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 10:24:39,997 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:24:53,175 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 10:26:48,670 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:27:25,142 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 10:30:02,626 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:30:40,142 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 10:31:24,965 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:32:01,269 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 10:33:02,040 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:33:38,279 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 10:34:45,461 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:39:59,862 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 10:41:31,709 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:46:41,480 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 10:46:52,960 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:51:09,108 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 10:57:11,833 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 12:10:25,223 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 12:16:31,092 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 12:21:53,856 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 12:27:56,622 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 13:16:06,795 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-24 13:16:06,796 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 13:16:38,550 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 13:23:23,017 - P0/1 - valkyrie.0 - WARNING - Wandb not available, skipping setup
2025-10-24 13:23:23,017 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 13:28:26,702 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 14:16:27,103 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 14:16:46,302 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 14:47:50,272 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 14:53:58,377 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 14:58:04,841 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 15:00:03,657 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761318003.6574752,
  "elapsed_time": 118.81656980514526
}
2025-10-24 15:00:03,658 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 15:00:03,659 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 15:00:50,227 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 15:02:49,242 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761318169.2421534,
  "elapsed_time": 119.01564598083496
}
2025-10-24 15:02:49,242 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 15:02:49,245 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 15:04:43,101 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 15:06:43,964 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761318403.9644096,
  "elapsed_time": 120.86387944221497
}
2025-10-24 15:06:43,965 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 15:06:43,965 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761318403.9652684,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761318403.9652743,
  "elapsed_time": 120.86474418640137
}
2025-10-24 15:06:43,965 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 15:06:43,965 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 15:08:57,973 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 15:10:57,361 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761318657.3609474,
  "elapsed_time": 119.38783979415894
}
2025-10-24 15:10:57,361 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 15:10:57,361 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761318657.3616989,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761318657.3617046,
  "elapsed_time": 119.38859724998474
}
2025-10-24 15:10:57,361 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 15:10:57,362 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 15:21:16,122 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 15:23:18,122 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761319398.1222851,
  "elapsed_time": 122.00007247924805
}
2025-10-24 15:23:18,122 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 15:23:18,123 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761319398.1230817,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761319398.1230884,
  "elapsed_time": 122.00087571144104
}
2025-10-24 15:23:18,123 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 15:23:23,021 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 15:33:48,722 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 15:35:12,945 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761320112.9448426,
  "elapsed_time": 84.22255730628967
}
2025-10-24 15:35:12,945 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 15:35:12,945 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761320112.9458282,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761320112.945834,
  "elapsed_time": 84.223548412323
}
2025-10-24 15:35:12,945 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 15:35:16,043 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 15:40:01,369 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 15:41:25,021 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761320485.020899,
  "elapsed_time": 83.65169668197632
}
2025-10-24 15:41:25,021 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 15:41:25,021 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761320485.0217636,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761320485.02177,
  "elapsed_time": 83.6525673866272
}
2025-10-24 15:41:25,021 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 15:41:28,011 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 15:56:00,870 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 15:58:03,840 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 16:00:00,674 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761321600.6745012,
  "elapsed_time": 116.83415102958679
}
2025-10-24 16:00:00,675 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 16:00:00,675 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761321600.675305,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761321600.6753118,
  "elapsed_time": 116.83496141433716
}
2025-10-24 16:00:00,675 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 16:00:05,535 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 16:05:49,033 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 16:07:14,302 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 16:09:12,127 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761322152.1273243,
  "elapsed_time": 117.82580065727234
}
2025-10-24 16:09:12,127 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 16:09:12,128 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761322152.1281168,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761322152.128123,
  "elapsed_time": 117.82659912109375
}
2025-10-24 16:09:12,128 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 16:09:16,933 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 16:12:39,885 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 16:14:37,004 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761322477.003924,
  "elapsed_time": 117.11918067932129
}
2025-10-24 16:14:37,004 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 16:14:37,004 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761322477.004835,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761322477.0048406,
  "elapsed_time": 117.12009716033936
}
2025-10-24 16:14:37,004 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 16:14:42,457 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 16:23:23,321 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 16:25:23,470 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761323123.470092,
  "elapsed_time": 120.14871048927307
}
2025-10-24 16:25:23,470 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 16:25:23,470 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761323123.4708402,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761323123.4708464,
  "elapsed_time": 120.14946484565735
}
2025-10-24 16:25:23,470 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 16:25:28,324 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 16:29:37,579 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 16:31:33,549 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761323493.5493646,
  "elapsed_time": 115.97060370445251
}
2025-10-24 16:31:33,550 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 16:31:33,550 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761323493.5501492,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761323493.5501547,
  "elapsed_time": 115.97139382362366
}
2025-10-24 16:31:33,550 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 16:31:38,632 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-24 17:16:54,904 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-24 17:18:54,307 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761326334.30728,
  "elapsed_time": 119.40378713607788
}
2025-10-24 17:18:54,308 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-24 17:18:54,308 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761326334.308148,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761326334.3081536,
  "elapsed_time": 119.40466070175171
}
2025-10-24 17:18:54,308 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-24 17:18:59,226 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-25 08:29:40,770 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-25 08:31:39,101 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761381099.1008954,
  "elapsed_time": 118.33095955848694
}
2025-10-25 08:31:39,101 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-25 08:31:39,101 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761381099.101699,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761381099.1017046,
  "elapsed_time": 118.33176875114441
}
2025-10-25 08:31:39,101 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-25 08:31:44,067 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-25 08:38:29,556 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-25 08:40:27,482 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761381627.481885,
  "elapsed_time": 117.92571210861206
}
2025-10-25 08:40:27,482 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-25 08:40:27,482 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761381627.482602,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761381627.4826076,
  "elapsed_time": 117.92643475532532
}
2025-10-25 08:40:27,482 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-25 08:40:32,403 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-25 08:43:42,696 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-25 08:45:54,154 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761381954.1544297,
  "elapsed_time": 131.45863580703735
}
2025-10-25 08:45:54,155 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-25 08:45:54,155 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761381954.1552415,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761381954.1552474,
  "elapsed_time": 131.4594533443451
}
2025-10-25 08:45:54,155 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-25 08:46:04,552 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-25 09:56:33,426 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-25 09:58:32,005 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761386312.0056095,
  "elapsed_time": 118.5797598361969
}
2025-10-25 09:58:32,006 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-25 09:58:32,006 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761386312.006336,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761386312.006342,
  "elapsed_time": 118.58049201965332
}
2025-10-25 09:58:32,006 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-25 09:58:37,067 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-25 10:13:08,524 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-25 10:13:49,534 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-25 10:16:13,130 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-25 10:18:10,294 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761387490.294147,
  "elapsed_time": 117.16407132148743
}
2025-10-25 10:18:10,294 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-25 10:18:10,294 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761387490.2948818,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761387490.2948878,
  "elapsed_time": 117.16481161117554
}
2025-10-25 10:18:10,295 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-25 10:18:15,240 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-25 10:24:52,670 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-25 10:26:52,336 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761388012.3362088,
  "elapsed_time": 119.66644215583801
}
2025-10-25 10:26:52,336 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-25 10:26:52,337 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761388012.3370707,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761388012.337078,
  "elapsed_time": 119.66731119155884
}
2025-10-25 10:26:52,337 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-25 10:26:57,209 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-25 10:44:33,727 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-25 10:46:32,532 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761389192.5317852,
  "elapsed_time": 118.80511975288391
}
2025-10-25 10:46:32,532 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-25 10:46:32,532 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761389192.5326753,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761389192.5326817,
  "elapsed_time": 118.80601572990417
}
2025-10-25 10:46:32,532 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-25 10:46:38,052 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-26 13:51:30,431 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-26 13:53:59,188 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761486839.1883204,
  "elapsed_time": 148.75698804855347
}
2025-10-26 13:53:59,189 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-26 13:53:59,189 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761486839.1892893,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761486839.189295,
  "elapsed_time": 148.7579619884491
}
2025-10-26 13:53:59,189 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-26 13:54:13,301 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-26 13:59:07,540 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-26 14:01:34,758 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761487294.7582355,
  "elapsed_time": 147.21876096725464
}
2025-10-26 14:01:34,758 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-26 14:01:34,759 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761487294.7589867,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761487294.7589931,
  "elapsed_time": 147.21951818466187
}
2025-10-26 14:01:34,759 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-26 14:01:53,348 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-26 14:10:30,026 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-26 14:12:59,876 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761487979.8762462,
  "elapsed_time": 149.85027241706848
}
2025-10-26 14:12:59,877 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-26 14:12:59,877 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761487979.8771951,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761487979.877202,
  "elapsed_time": 149.85122776031494
}
2025-10-26 14:12:59,877 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-26 14:13:12,897 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-26 15:15:12,120 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-26 15:17:42,521 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761491862.5213792,
  "elapsed_time": 150.40184783935547
}
2025-10-26 15:17:42,522 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-26 15:17:42,522 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761491862.5222993,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761491862.5223055,
  "elapsed_time": 150.40277361869812
}
2025-10-26 15:17:42,522 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-26 15:17:55,653 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-26 15:52:11,344 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-26 15:54:38,602 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761494078.6016777,
  "elapsed_time": 147.25752997398376
}
2025-10-26 15:54:38,602 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-26 15:54:38,602 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761494078.602718,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761494078.6027243,
  "elapsed_time": 147.25857639312744
}
2025-10-26 15:54:38,602 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-26 15:54:55,056 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-26 15:59:10,052 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-26 16:01:37,270 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761494497.2700577,
  "elapsed_time": 147.2178704738617
}
2025-10-26 16:01:37,270 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-26 16:01:37,270 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761494497.2708843,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761494497.27089,
  "elapsed_time": 147.21870255470276
}
2025-10-26 16:01:37,271 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-26 16:01:53,367 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-26 16:08:10,280 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-26 16:10:51,814 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761495051.8146813,
  "elapsed_time": 161.53490471839905
}
2025-10-26 16:10:51,815 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-26 16:10:51,815 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761495051.8154235,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761495051.8154297,
  "elapsed_time": 161.53565287590027
}
2025-10-26 16:10:51,815 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-26 16:11:08,657 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-26 16:24:17,930 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-26 16:26:44,483 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761496004.4831302,
  "elapsed_time": 146.5530560016632
}
2025-10-26 16:26:44,484 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-26 16:26:44,484 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761496004.4841235,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761496004.4841294,
  "elapsed_time": 146.55405497550964
}
2025-10-26 16:26:44,484 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-26 16:27:00,895 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 09:16:02,268 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 09:18:30,159 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761556710.1593368,
  "elapsed_time": 147.8911464214325
}
2025-10-27 09:18:30,160 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 09:18:30,160 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761556710.1602526,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761556710.1602585,
  "elapsed_time": 147.89206767082214
}
2025-10-27 09:18:30,160 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 09:18:58,205 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 09:45:23,657 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 09:47:49,925 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761558469.9254508,
  "elapsed_time": 146.2682945728302
}
2025-10-27 09:47:49,926 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 09:47:49,926 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761558469.9262407,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761558469.9262464,
  "elapsed_time": 146.2690896987915
}
2025-10-27 09:47:49,926 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 09:48:05,533 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 10:02:48,353 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 10:04:15,506 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761559455.5058386,
  "elapsed_time": 87.15312767028809
}
2025-10-27 10:04:15,506 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 10:04:15,506 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761559455.506651,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761559455.5066571,
  "elapsed_time": 87.15394592285156
}
2025-10-27 10:04:15,506 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 10:04:23,249 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 10:10:35,366 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 10:10:50,190 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 10:11:40,142 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 10:13:07,762 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761559987.7618837,
  "elapsed_time": 87.61974000930786
}
2025-10-27 10:13:07,762 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 10:13:07,763 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761559987.7630424,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761559987.7630477,
  "elapsed_time": 87.62090373039246
}
2025-10-27 10:13:07,763 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 10:13:33,031 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 10:15:43,260 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 10:17:09,099 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761560229.0988832,
  "elapsed_time": 85.83881330490112
}
2025-10-27 10:17:09,099 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 10:17:09,099 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761560229.0996788,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761560229.0996847,
  "elapsed_time": 85.83961462974548
}
2025-10-27 10:17:09,099 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 10:17:18,774 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 10:19:35,212 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 10:21:02,736 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761560462.7366858,
  "elapsed_time": 87.52447557449341
}
2025-10-27 10:21:02,737 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 10:21:02,737 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761560462.737435,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761560462.737441,
  "elapsed_time": 87.52523064613342
}
2025-10-27 10:21:02,737 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 10:21:10,696 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 10:24:15,650 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 10:25:43,919 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761560743.9190009,
  "elapsed_time": 88.26905989646912
}
2025-10-27 10:25:43,920 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 10:25:43,920 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761560743.9205291,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761560743.9205353,
  "elapsed_time": 88.27059388160706
}
2025-10-27 10:25:43,920 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 10:26:09,205 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 10:31:08,438 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 10:33:34,475 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761561214.4753053,
  "elapsed_time": 146.03707313537598
}
2025-10-27 10:33:34,476 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 10:33:34,476 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761561214.476468,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761561214.476474,
  "elapsed_time": 146.03824138641357
}
2025-10-27 10:33:34,476 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 10:34:08,013 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 10:39:29,173 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 10:41:55,650 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761561715.6507456,
  "elapsed_time": 146.47786498069763
}
2025-10-27 10:41:55,651 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 10:41:55,651 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761561715.6515033,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761561715.6515095,
  "elapsed_time": 146.47862839698792
}
2025-10-27 10:41:55,651 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 10:42:29,475 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 10:48:48,761 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 12:47:04,484 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 12:49:48,350 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761569388.3501804,
  "elapsed_time": 163.86573767662048
}
2025-10-27 12:49:48,351 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 12:49:48,351 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761569388.3512836,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761569388.351289,
  "elapsed_time": 163.86684560775757
}
2025-10-27 12:49:48,351 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 12:50:24,992 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 13:49:29,884 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 13:51:55,900 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761573115.9006088,
  "elapsed_time": 146.01683259010315
}
2025-10-27 13:51:55,901 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 13:51:55,901 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761573115.9014153,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761573115.9014208,
  "elapsed_time": 146.0176441669464
}
2025-10-27 13:51:55,901 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 13:53:30,178 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 13:57:21,225 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 13:59:13,054 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 13:59:24,317 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 14:01:50,207 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761573710.2076645,
  "elapsed_time": 145.89044046401978
}
2025-10-27 14:01:50,208 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 14:01:50,208 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761573710.208574,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761573710.2085795,
  "elapsed_time": 145.8913552761078
}
2025-10-27 14:01:50,208 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 14:03:26,204 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 14:16:26,434 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 14:18:54,412 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761574734.4124076,
  "elapsed_time": 147.9781723022461
}
2025-10-27 14:18:54,413 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 14:18:54,413 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761574734.413331,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761574734.4133365,
  "elapsed_time": 147.97910070419312
}
2025-10-27 14:18:54,413 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 14:20:27,834 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 14:28:44,977 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 14:31:11,547 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761575471.546857,
  "elapsed_time": 146.56945371627808
}
2025-10-27 14:31:11,547 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 14:31:11,548 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761575471.5480614,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761575471.5480678,
  "elapsed_time": 146.57066369056702
}
2025-10-27 14:31:11,548 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 14:32:45,456 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 14:46:09,691 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 14:48:22,527 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761576502.5275538,
  "elapsed_time": 132.83675003051758
}
2025-10-27 14:48:22,528 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 14:48:22,528 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761576502.528337,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761576502.5283463,
  "elapsed_time": 132.83754205703735
}
2025-10-27 14:48:22,528 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 14:49:58,141 - P0/1 - valkyrie.0 - INFO - Logger closed
2025-10-27 15:08:07,238 - P0/1 - valkyrie.0 - INFO - Multi-host logger initialized for process 0/1
2025-10-27 15:10:04,088 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "model/total_parameters": 978997250,
  "model/parameter_millions": 978.99725,
  "model/parameter_billions": 0.97899725,
  "config/vocab_size": 32000,
  "config/d_model": 1536,
  "config/n_layers": 36,
  "config/n_heads": 24,
  "config/n_kv_heads": 24,
  "config/original_max_position_embeddings": 4096,
  "config/max_position_embeddings": 65536,
  "config/rope_theta": 10000.0,
  "config/yarn_beta_fast": 32.0,
  "config/yarn_beta_slow": 1.0,
  "config/attn_dropout": 0.0,
  "config/resid_dropout": 0.0,
  "config/ffn_dropout": 0.1,
  "config/use_bias": false,
  "config/layer_norm_eps": 1e-05,
  "config/initializer_range": 0.02,
  "config/s5_state_dim": 768,
  "config/use_s5": true,
  "config/gradient_clipping": 1.0,
  "config/weight_decay": 0.1,
  "config/gradient_checkpointing": true,
  "config/use_bigbird_attention": true,
  "config/bigbird_block_size": 128,
  "config/bigbird_num_global_tokens": 16,
  "config/bigbird_num_window_blocks": 3,
  "config/bigbird_num_random_blocks": 3,
  "config/bigbird_use_blockified_gemm": true,
  "config/use_longformer_attention": false,
  "config/longformer_window_size": 64,
  "config/longformer_chunked": true,
  "config/longformer_chunk_size": 32,
  "config/longformer_use_full_attention_fallback": false,
  "config/use_hrm": true,
  "config/hrm_plan_length": 32,
  "config/hrm_H_cycles": 3,
  "config/hrm_L_cycles": 3,
  "config/hrm_H_layers": 6,
  "config/hrm_L_layers": 6,
  "config/hrm_intermediate_size": 6144,
  "config/hrm_use_act": true,
  "config/hrm_act_threshold": 0.9,
  "config/hrm_planner_layers": 2,
  "config/hrm_executor_steps": 4,
  "config/hrm_planner_update_frequency": 4,
  "config/hrm_use_act_halting": true,
  "config/hrm_one_step_gradient": true,
  "config/hrm_deep_supervision": true,
  "config/rope_scaling_factor": 16.0,
  "process_index": 0,
  "timestamp": 1761577804.0881753,
  "elapsed_time": 116.8500463962555
}
2025-10-27 15:10:04,088 - P0/1 - valkyrie.0 - INFO - Model initialized with 978,997,250 parameters (0.98B)
2025-10-27 15:10:04,089 - P0/1 - valkyrie.0 - INFO - Metrics: {
  "training/total_steps": 100000,
  "training/process_count": 1,
  "training/start_time": 1761577804.0890064,
  "dataset/sources": 4,
  "process_index": 0,
  "timestamp": 1761577804.089013,
  "elapsed_time": 116.8508837223053
}
2025-10-27 15:10:04,089 - P0/1 - valkyrie.0 - INFO - Training started: 100000 steps on 1 processes
2025-10-27 15:11:46,829 - P0/1 - valkyrie.0 - INFO - Logger closed
